{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticker Codes\n",
    "from nsetools import Nse\n",
    "# Raw Package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Data Source\n",
    "import yfinance as yf\n",
    "#Data viz\n",
    "import plotly.graph_objs as go\n",
    "#pywidget\n",
    "import ipywidgets as widget\n",
    "from IPython.display import display\n",
    "import talib\n",
    "import trendln\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# from helper_functions import get_user_inputs, create_top_line, create_bottom_line, pull_price_data, plot_graph, isSupport, isResistance, isFarFromLevel, finding_signals_from_data, is_consolidating, is_breaking_out, technical_scoring_function, long_term_trend_scoring_function\n",
    "from helper_functions import *\n",
    "import helper_functions\n",
    "import importlib\n",
    "importlib.reload(helper_functions)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get technical_score_df from technical_scoring_function\n",
    "#Test this function with only one ticker. Should return data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('Select company name from drop down')\n",
    "# nse = Nse()\n",
    "# company_dict = nse.get_stock_codes()\n",
    "# stock_ticker = widget.Dropdown(options=list(company_dict.values())[1:], value=  '20 Microns Limited', description='Stock:')\n",
    "# stock_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zxdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perpro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zxdf, pro, perpro = backtest_function(mode = \"ACC.NS\",live = 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Backtesting function\n",
    "# def backtest_function(mode = 'all', period = -2, live = 'no', csv_file = 'n50.csv', cur_thresh = 5):\n",
    "#     tpm = 3 \n",
    "#     if(mode == 'all'):\n",
    "#         n50 = pd.read_csv(csv_file)\n",
    "#         nifty50 = []\n",
    "#         for t in n50['Symbol'].values:\n",
    "#             nifty50.append(t+'.NS')\n",
    "#         for t in nifty50:\n",
    "#             ticker = t\n",
    "#             #print(live)\n",
    "#             data = pull_price_data(live, t, mode = 'scoring')\n",
    "#             if(live == 'no'):\n",
    "#                 data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 1)\n",
    "#             else:\n",
    "#                 data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = tpm)\n",
    "#             data = plot_graph(data, g_type, mode = 'scoring')\n",
    "            \n",
    "#             technical_score_column_list = []\n",
    "#             for col in data.columns:\n",
    "#                 if(col.startswith('final_score_technical')):\n",
    "#                     technical_score_column_list.append(col)\n",
    "\n",
    "#             backtest_df = data.copy()\n",
    "#             long_profit_loss_calculation_df = pd.DataFrame(columns = ['Buy Date', 'Buy Price', 'Buy Signal', \n",
    "#                                                                       'isDone', 'Sell Date', 'Sell Price',\n",
    "#                                                                       'Stop Loss', 'Target', 'Profit Percentage'])\n",
    "#             if(live == 'yes'):\n",
    "#                 technical_score_column_list.remove('final_score_technical_DOJI-')\n",
    "#                 technical_score_column_list.remove('final_score_technical_DOJI+')\n",
    "#             period = 2\n",
    "#             for i in range(0 , len(data) - 1, 1):\n",
    "#                 #Dropping doji for live data\n",
    "#                 #if(live=='yes'):\n",
    "#                 #    backtest_df.drop(columns = ['final_score_technical_DOJI-', 'final_score_technical_DOJI+'], inplace = True)\n",
    "\n",
    "#                 #df of 2 days to match techincal scoring function      \n",
    "#                 two_day_score = backtest_df.iloc[i:i+2]\n",
    "\n",
    "#                 # Adjusting score for volume\n",
    "#                 if(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) > 0):\n",
    "#                     if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "#                         current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) + 1\n",
    "#                     else:\n",
    "#                         current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "#                 elif(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) < 0):\n",
    "#                     if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "#                         current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) - 1\n",
    "#                     else:\n",
    "#                         current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "#                 current_market_price = two_day_score['Adj Close'].iloc[-1]\n",
    "#                 current_date = two_day_score.index[-1]\n",
    "#                 if(live == 'yes'):\n",
    "#                     stop_loss_multiplier = 0.995\n",
    "#                     target_multiplier = 1.01\n",
    "#                 else:\n",
    "#                     stop_loss_multiplier = 0.95\n",
    "#                     target_multiplier = 1.1\n",
    "#                 if(current_score >= cur_thresh):\n",
    "#                     temp_row = {\"Buy Date\": current_date, \"Buy Price\": current_market_price, \"Buy Signal\" : current_score, \n",
    "#                                 \"isDone\" : 0, \"Stop Loss\": current_market_price * stop_loss_multiplier, \n",
    "#                                 \"Target\" : current_market_price * target_multiplier, \"Threshold\" : cur_thresh,\n",
    "#                                \"ticker\" : t}\n",
    "#                     long_profit_loss_calculation_df = long_profit_loss_calculation_df.append(temp_row, ignore_index = True)\n",
    "\n",
    "#                 #Checking if price is above or below SL. Target\n",
    "#                 if(len(long_profit_loss_calculation_df) > 0):\n",
    "#                     to_be_checked_df = long_profit_loss_calculation_df[long_profit_loss_calculation_df['isDone'] == 0]\n",
    "#                     for j in (to_be_checked_df.index):\n",
    "\n",
    "#                         if(to_be_checked_df.loc[j]['Target'] < current_market_price):\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"isDone\"] = 1\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100\n",
    "#                         elif(to_be_checked_df.loc[j]['Stop Loss'] > current_market_price):\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"isDone\"] = -1\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "#                             long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100\n",
    "#             break\n",
    "        \n",
    "#         overall_profit = long_profit_loss_calculation_df['Profit Percentage'].sum()\n",
    "#         good_calls = (len(long_profit_loss_calculation_df[long_profit_loss_calculation_df['Profit Percentage'] > 0]) - len(long_profit_loss_calculation_df[long_profit_loss_calculation_df['Profit Percentage'] < 0]))/len(long_profit_loss_calculation_df)\n",
    "#         return(long_profit_loss_calculation_df, overall_profit, good_calls)\n",
    "#     else:\n",
    "#         print(\"else\")\n",
    "#         ticker = t = mode\n",
    "#         data = pull_price_data(live, t, mode = 'scoring')\n",
    "#         if(live == 'no'):\n",
    "#             data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 1)\n",
    "#         else:\n",
    "#             data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = tpm)\n",
    "#         data = plot_graph(data, g_type, mode = 'scoring')\n",
    "\n",
    "#         technical_score_column_list = []\n",
    "#         for col in data.columns:\n",
    "#             if(col.startswith('final_score_technical')):\n",
    "#                 technical_score_column_list.append(col)\n",
    "\n",
    "#         backtest_df = data.copy()\n",
    "#         long_profit_loss_calculation_df = pd.DataFrame(columns = ['Buy Date', 'Buy Price', 'Buy Signal', \n",
    "#                                                                   'isDone', 'Sell Date', 'Sell Price',\n",
    "#                                                                   'Stop Loss', 'Target', 'Profit Percentage'])\n",
    "#         #print(long_profit_loss_calculation_df)\n",
    "#         if(live == 'yes'):\n",
    "#             technical_score_column_list.remove('final_score_technical_DOJI-')\n",
    "#             technical_score_column_list.remove('final_score_technical_DOJI+')\n",
    "#         period = 2\n",
    "#         for i in range(0 , len(data) - 1, 1):\n",
    "#             #Dropping doji for live data\n",
    "#             #if(live=='yes'):\n",
    "#             #    backtest_df.drop(columns = ['final_score_technical_DOJI-', 'final_score_technical_DOJI+'], inplace = True)\n",
    "\n",
    "#             #df of 2 days to match techincal scoring function      \n",
    "#             two_day_score = backtest_df.iloc[i:i+2]\n",
    "\n",
    "#             # Adjusting score for volume\n",
    "#             if(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) > 0):\n",
    "#                 if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "#                     current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) + 1\n",
    "#                 else:\n",
    "#                     current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "#             elif(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) < 0):\n",
    "#                 if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "#                     current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) - 1\n",
    "#                 else:\n",
    "#                     current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "#             current_market_price = two_day_score['Adj Close'].iloc[-1]\n",
    "#             current_date = two_day_score.index[-1]\n",
    "#             if(live == 'yes'):\n",
    "#                 stop_loss_multiplier = 0.995\n",
    "#                 target_multiplier = 1.01\n",
    "#             else:\n",
    "#                 stop_loss_multiplier = 0.95\n",
    "#                 target_multiplier = 1.1\n",
    "#             if(current_score >= cur_thresh):\n",
    "#                 temp_row = {\"Buy Date\": current_date, \"Buy Price\": current_market_price, \"Buy Signal\" : current_score, \n",
    "#                             \"isDone\" : 0, \"Stop Loss\": current_market_price * stop_loss_multiplier, \n",
    "#                             \"Target\" : current_market_price * target_multiplier, \"Threshold\" : cur_thresh,\n",
    "#                            \"ticker\" : t}\n",
    "#                 long_profit_loss_calculation_df = long_profit_loss_calculation_df.append(temp_row, ignore_index = True)\n",
    "\n",
    "#             #Checking if price is above or below SL. Target\n",
    "#             if(len(long_profit_loss_calculation_df) > 0):\n",
    "#                 to_be_checked_df = long_profit_loss_calculation_df[long_profit_loss_calculation_df['isDone'] == 0]\n",
    "#                 for j in (to_be_checked_df.index):\n",
    "\n",
    "#                     if(to_be_checked_df.loc[j]['Target'] < current_market_price):\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"isDone\"] = 1\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100\n",
    "#                     elif(to_be_checked_df.loc[j]['Stop Loss'] > current_market_price):\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"isDone\"] = -1\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "#                         long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100\n",
    "            \n",
    "#         #print(len(long_profit_loss_calculation_df))\n",
    "#         #print(long_profit_loss_calculation_df)\n",
    "#         overall_profit = long_profit_loss_calculation_df['Profit Percentage'].sum()\n",
    "#         good_calls = (len(long_profit_loss_calculation_df[long_profit_loss_calculation_df['Profit Percentage'] > 0]) - len(long_profit_loss_calculation_df[long_profit_loss_calculation_df['Profit Percentage'] < 0]))/len(long_profit_loss_calculation_df)\n",
    "#     return(long_profit_loss_calculation_df, overall_profit, good_calls)\n",
    "\n",
    "# # #Getting data for single stock\n",
    "# # live, g_type = get_user_inputs()\n",
    "# # data = pull_price_data(live, stock_ticker = 'TATAMOTORS.NS')\n",
    "# # print(data.index[-1])\n",
    "\n",
    "# # if(live == 'yes'):\n",
    "# #     print(\"Is Consolidating: \",is_consolidating(data, percentage=0.5))\n",
    "# # else:\n",
    "# #     print(\"Is Consolidating: \",is_consolidating(data))\n",
    "\n",
    "    \n",
    "# # if(live == 'yes'):\n",
    "# #     print(\"Is Breaking Out: \",is_breaking_out(data, percentage=2))\n",
    "# # else:\n",
    "# #     print(\"Is Breaking Out: \",is_breaking_out(data))    \n",
    "\n",
    "# # if(live == 'no' or live == 'max'):\n",
    "# #     data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 1)\n",
    "# # else:\n",
    "# #     data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 3)\n",
    "# # #print(levels)\n",
    "# # data = data[data['Close'].notna()]\n",
    "# # #plot_graph(data, g_type='line', mode = 'quick')\n",
    "# # data = plot_graph(data, g_type, mode = 'scoring')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if(live == 'yes'):\n",
    "# #     technical_score_column_list.remove('final_score_technical_DOJI-')\n",
    "# #     technical_score_column_list.remove('final_score_technical_DOJI+')\n",
    "\n",
    "# # cur_thresh = 5\n",
    "# # period = 2\n",
    "# # for i in range(0 , len(data) - 1, 1):\n",
    "# #     #Dropping doji for live data\n",
    "# #     #if(live=='yes'):\n",
    "# #     #    backtest_df.drop(columns = ['final_score_technical_DOJI-', 'final_score_technical_DOJI+'], inplace = True)\n",
    "        \n",
    "# #     #df of 2 days to match techincal scoring function      \n",
    "# #     two_day_score = backtest_df.iloc[i:i+2]\n",
    "    \n",
    "# #     # Adjusting score for volume\n",
    "# #     if(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) > 0):\n",
    "# #         if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "# #             current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) + 1\n",
    "# #         else:\n",
    "# #             current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "# #     elif(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) < 0):\n",
    "# #         if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "# #             current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) - 1\n",
    "# #         else:\n",
    "# #             current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "# #     current_market_price = two_day_score['Adj Close'].iloc[-1]\n",
    "# #     current_date = two_day_score.index[-1]\n",
    "# #     if(live == 'yes'):\n",
    "# #         stop_loss_multiplier = 0.997\n",
    "# #         target_multiplier = 1.008\n",
    "# #     else:\n",
    "# #         stop_loss_multiplier = 0.97\n",
    "# #         target_multiplier = 1.5\n",
    "# #     if(current_score >= cur_thresh):\n",
    "# #         temp_row = {\"Buy Date\": current_date, \"Buy Price\": current_market_price, \"Buy Signal\" : current_score, \n",
    "# #                     \"isDone\" : 0, \"Stop Loss\": current_market_price * stop_loss_multiplier, \n",
    "# #                     \"Target\" : current_market_price * target_multiplier, \"Threshold\" : cur_thresh,\n",
    "# #                    \"ticker\" : backtest_ticker}\n",
    "# #         long_profit_loss_calculation_df = long_profit_loss_calculation_df.append(temp_row, ignore_index = True)\n",
    "    \n",
    "# #     #Checking if price is above or below SL. Target\n",
    "# #     if(len(long_profit_loss_calculation_df) > 0):\n",
    "# #         to_be_checked_df = long_profit_loss_calculation_df[long_profit_loss_calculation_df['isDone'] == 0]\n",
    "# #         for j in (to_be_checked_df.index):\n",
    "            \n",
    "# #             if(to_be_checked_df.loc[j]['Target'] < current_market_price):\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"isDone\"] = 1\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100\n",
    "# #             elif(to_be_checked_df.loc[j]['Stop Loss'] > current_market_price):\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"isDone\"] = -1\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "# #                 long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting data for single stock\n",
    "live, g_type = get_user_inputs()\n",
    "data = pull_price_data(live, stock_ticker = 'BIOCON.NS')\n",
    "print(data.index[-1])\n",
    "\n",
    "if(live == 'yes'):\n",
    "    print(\"Is Consolidating: \",is_consolidating(data, percentage=0.5))\n",
    "else:\n",
    "    print(\"Is Consolidating: \",is_consolidating(data))\n",
    "\n",
    "    \n",
    "if(live == 'yes'):\n",
    "    print(\"Is Breaking Out: \",is_breaking_out(data, percentage=2))\n",
    "else:\n",
    "    print(\"Is Breaking Out: \",is_breaking_out(data))    \n",
    "\n",
    "if(live == 'no' or live == 'max'):\n",
    "    data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 1)\n",
    "else:\n",
    "    data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 3)\n",
    "print(levels)\n",
    "data = data[data['Close'].notna()]\n",
    "plot_graph(data, g_type='line', mode = 'quick', plot_sup_res = plot_sup_res)\n",
    "data = plot_graph(data, g_type, plot_sup_res = plot_sup_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_score_technical_Volume</th>\n",
       "      <th>final_score_technical__RSI+</th>\n",
       "      <th>final_score_technical__RSI-</th>\n",
       "      <th>final_score_technical_MACD+</th>\n",
       "      <th>final_score_technical_MACD-</th>\n",
       "      <th>final_score_technical_BB+</th>\n",
       "      <th>final_score_technical_BB-</th>\n",
       "      <th>final_score_technical_supres+</th>\n",
       "      <th>final_score_technical_supres-</th>\n",
       "      <th>final_score_technical_CDL3INSIDE-</th>\n",
       "      <th>...</th>\n",
       "      <th>final_score_technical_CDLSEPARATINGLINES-</th>\n",
       "      <th>final_score_technical_CDL3INSIDE+</th>\n",
       "      <th>final_score_technical_CDL3OUTSIDE+</th>\n",
       "      <th>final_score_technical_CDLHAMMER+</th>\n",
       "      <th>final_score_technical_CDLINVERTEDHAMMER+</th>\n",
       "      <th>final_score_technical_CDLMORNINGSTAR+</th>\n",
       "      <th>final_score_technical_CDLSEPARATINGLINES+</th>\n",
       "      <th>final_score_technical_CDLUNIQUE3RIVER+</th>\n",
       "      <th>final_score_technical_DOJI-</th>\n",
       "      <th>final_score_technical_DOJI+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            final_score_technical_Volume  final_score_technical__RSI+  \\\n",
       "Date                                                                    \n",
       "2022-07-14                           1.0                          NaN   \n",
       "2022-07-15                           NaN                          NaN   \n",
       "\n",
       "            final_score_technical__RSI-  final_score_technical_MACD+  \\\n",
       "Date                                                                   \n",
       "2022-07-14                          NaN                          NaN   \n",
       "2022-07-15                          NaN                          NaN   \n",
       "\n",
       "            final_score_technical_MACD-  final_score_technical_BB+  \\\n",
       "Date                                                                 \n",
       "2022-07-14                          NaN                        0.5   \n",
       "2022-07-15                          NaN                        NaN   \n",
       "\n",
       "            final_score_technical_BB-  final_score_technical_supres+  \\\n",
       "Date                                                                   \n",
       "2022-07-14                        NaN                            NaN   \n",
       "2022-07-15                        NaN                            NaN   \n",
       "\n",
       "            final_score_technical_supres-  final_score_technical_CDL3INSIDE-  \\\n",
       "Date                                                                           \n",
       "2022-07-14                            NaN                                NaN   \n",
       "2022-07-15                            NaN                                NaN   \n",
       "\n",
       "            ...  final_score_technical_CDLSEPARATINGLINES-  \\\n",
       "Date        ...                                              \n",
       "2022-07-14  ...                                        NaN   \n",
       "2022-07-15  ...                                        NaN   \n",
       "\n",
       "            final_score_technical_CDL3INSIDE+  \\\n",
       "Date                                            \n",
       "2022-07-14                                NaN   \n",
       "2022-07-15                                NaN   \n",
       "\n",
       "            final_score_technical_CDL3OUTSIDE+  \\\n",
       "Date                                             \n",
       "2022-07-14                                 NaN   \n",
       "2022-07-15                                 NaN   \n",
       "\n",
       "            final_score_technical_CDLHAMMER+  \\\n",
       "Date                                           \n",
       "2022-07-14                               NaN   \n",
       "2022-07-15                               NaN   \n",
       "\n",
       "            final_score_technical_CDLINVERTEDHAMMER+  \\\n",
       "Date                                                   \n",
       "2022-07-14                                       NaN   \n",
       "2022-07-15                                       NaN   \n",
       "\n",
       "            final_score_technical_CDLMORNINGSTAR+  \\\n",
       "Date                                                \n",
       "2022-07-14                                    NaN   \n",
       "2022-07-15                                    NaN   \n",
       "\n",
       "            final_score_technical_CDLSEPARATINGLINES+  \\\n",
       "Date                                                    \n",
       "2022-07-14                                        NaN   \n",
       "2022-07-15                                        NaN   \n",
       "\n",
       "            final_score_technical_CDLUNIQUE3RIVER+  \\\n",
       "Date                                                 \n",
       "2022-07-14                                     NaN   \n",
       "2022-07-15                                     NaN   \n",
       "\n",
       "            final_score_technical_DOJI-  final_score_technical_DOJI+  \n",
       "Date                                                                  \n",
       "2022-07-14                          NaN                          NaN  \n",
       "2022-07-15                          NaN                          NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = technical_scoring_function(mode = 'INTC', live = 'no')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-16 14:45:07.661087\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CADILAHC.NS: No data found, symbol may be delisted\n",
      "Error with CADILAHC.NS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "All Done\n",
      "[('PETRONET.NS', 4.0), ('MCDOWELL-N.NS', 3.0), ('INDUSTOWER.NS', 2.67), ('MRF.NS', 2.67), ('DABUR.NS', 2.0), ('MARICO.NS', 2.0), ('NMDC.NS', 2.0), ('PIDILITIND.NS', 2.0), ('ALKEM.NS', 1.5), ('MUTHOOTFIN.NS', 1.5), ('TORNTPHARM.NS', 1.17), ('AMBUJACEM.NS', 1.0), ('GAIL.NS', 1.0), ('ICICIGI.NS', 1.0), ('IGL.NS', 1.0), ('MOTHERSUMI.NS', 1.0), ('BIOCON.NS', 0.0), ('COLPAL.NS', 0.0), ('DLF.NS', 0.0), ('GODREJCP.NS', 0.0), ('NAUKRI.NS', 0.0), ('JUBLFOOD.NS', 0.0), ('PEL.NS', 0.0), ('SBICARD.NS', 0.0), ('HAVELLS.NS', -0.33), ('AUROPHARMA.NS', -1.0), ('DMART.NS', -1.0), ('ADANITRANS.NS', -1.33), ('UBL.NS', -1.33), ('BERGEPAINT.NS', -1.5), ('ADANIGREEN.NS', -2.0), ('SIEMENS.NS', -2.33), ('ACC.NS', -3.0), ('BAJAJHLDNG.NS', -3.0)] \n",
      "\n",
      "\n",
      "\n",
      "0:00:23.323084\n"
     ]
    }
   ],
   "source": [
    "#Scoring function (Gives Signal of Reversal)\n",
    "# personal list = ['BIOCON.NS','COLPAL.NS']\n",
    "start = datetime.datetime.now()\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "pos_score_company, neg_score_company = technical_scoring_function(live = 'no', csv_file = 'n50.csv') #live, period, ticker as params\n",
    "print('All Done')\n",
    "\n",
    "pos_score_company = sorted(pos_score_company.items(), key=lambda x: x[1], reverse = True)\n",
    "#neg_score_company = sorted(neg_score_company.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "print(pos_score_company,'\\n\\n\\n')\n",
    "#print(neg_score_company)\n",
    "print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-16 14:46:02.522596\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CADILAHC.NS: No data found, symbol may be delisted\n",
      "Error with CADILAHC.NS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "All Done\n",
      "[] \n",
      "\n",
      "\n",
      "\n",
      "[('BERGEPAINT.NS', -7.0), ('MOTHERSUMI.NS', -3.5), ('NMDC.NS', -3.0299999999999994), ('NAUKRI.NS', -2.5), ('AUROPHARMA.NS', -2.0), ('MUTHOOTFIN.NS', -1.5199999999999996), ('LTI.NS', -1.5), ('ICICIPRULI.NS', -1.33), ('INDUSTOWER.NS', -1.33), ('BIOCON.NS', -0.5), ('JUBLFOOD.NS', -0.5), ('SIEMENS.NS', -0.47000000000000064), ('MRF.NS', -0.33000000000000007), ('BOSCHLTD.NS', -0.16000000000000014), ('DMART.NS', 0.0), ('DLF.NS', 0.0), ('TORNTPHARM.NS', 0.16999999999999993), ('GAIL.NS', 0.33000000000000007), ('INDIGO.NS', 0.33000000000000007), ('BANDHANBNK.NS', 0.8300000000000001), ('PIDILITIND.NS', 0.8300000000000001), ('HDFCAMC.NS', 1.0), ('PEL.NS', 1.0), ('YESBANK.NS', 1.0), ('UBL.NS', 1.1799999999999997), ('BAJAJHLDNG.NS', 1.6600000000000001), ('VEDL.NS', 1.950000000000001), ('LUPIN.NS', 2.0), ('MCDOWELL-N.NS', 2.0), ('SBICARD.NS', 2.01), ('ADANIENT.NS', 2.5), ('ALKEM.NS', 2.5), ('APOLLOHOSP.NS', 2.5), ('PETRONET.NS', 3.33), ('IGL.NS', 4.0), ('ICICIGI.NS', 4.16), ('COLPAL.NS', 4.5), ('PGHH.NS', 4.5), ('AMBUJACEM.NS', 5.0), ('ACC.NS', 5.33), ('MARICO.NS', 6.0), ('HINDPETRO.NS', 6.15), ('ADANIGREEN.NS', 6.17), ('HAVELLS.NS', 6.34), ('ABBOTINDIA.NS', 8.0), ('DABUR.NS', 8.5), ('ADANITRANS.NS', 9.35), ('GODREJCP.NS', 13.17)]\n"
     ]
    }
   ],
   "source": [
    "#Scoring function (Gives Longterm Trend)\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "long_neg_score_company, long_pos_score_company = long_term_trend_scoring_function(live = 'no', csv_file = 'n50.csv') #live, period, ticker as params\n",
    "print('All Done')\n",
    "\n",
    "long_pos_score_company = sorted(long_pos_score_company.items(), key=lambda x: x[1], reverse = True)\n",
    "long_neg_score_company = sorted(long_neg_score_company.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "print(long_pos_score_company,'\\n\\n\\n')\n",
    "print(long_neg_score_company)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "All Done\n",
      "[('BIOCON.NS', 0.0), ('COLPAL.NS', 0.0)] \n",
      "\n",
      "\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Scoring function (Gives Signal of Reversal)\n",
    "# personal list = ['BIOCON.NS','COLPAL.NS']\n",
    "pos_score_company, neg_score_company = technical_scoring_function(mode = \"list\") #live, period, ticker as params\n",
    "print('All Done')\n",
    "\n",
    "pos_score_company = sorted(pos_score_company.items(), key=lambda x: x[1], reverse = True)\n",
    "neg_score_company = sorted(neg_score_company.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "print(pos_score_company,'\\n\\n\\n')\n",
    "print(neg_score_company)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "All Done\n",
      "[] \n",
      "\n",
      "\n",
      "\n",
      "[('BIOCON.NS', -0.5), ('COLPAL.NS', 4.5)]\n"
     ]
    }
   ],
   "source": [
    "#Scoring function (Gives Longterm Trend)\n",
    "neg_score_company, pos_score_company = long_term_trend_scoring_function(mode = 'list') #live, period, ticker as params\n",
    "print('All Done')\n",
    "\n",
    "pos_score_company = sorted(pos_score_company.items(), key=lambda x: x[1], reverse = True)\n",
    "neg_score_company = sorted(neg_score_company.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "print(pos_score_company,'\\n\\n\\n')\n",
    "print(neg_score_company)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops for continuous running for live data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Error with ACC.NS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Error with APOLLOHOSP.NS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Error with BIOCON.NS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CADILAHC.NS: No data found, symbol may be delisted\n",
      "Error with CADILAHC.NS\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-afef9bdc57c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-afef9bdc57c1>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mpos_score_company\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_score_company\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtechnical_scoring_function\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'yes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'n50.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#live, period, ticker as params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m#pos_score_company = sorted(pos_score_company.items(), key=lambda x: x[1], reverse = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#neg_score_company = sorted(neg_score_company.items(), key=lambda x: x[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Stock Market Project\\Stock-Scoring\\helper_functions.py\u001b[0m in \u001b[0;36mtechnical_scoring_function\u001b[1;34m(mode, period, live, csv_file)\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[0mticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;31m#print(live)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpull_price_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'scoring'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlive\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Stock Market Project\\Stock-Scoring\\helper_functions.py\u001b[0m in \u001b[0;36mpull_price_data\u001b[1;34m(live, stock_ticker, mode)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlive\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'yes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'1m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtzinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Date'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\yfinance\\multi.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, group_by, auto_adjust, back_adjust, progress, period, show_errors, interval, prepost, proxy, rounding, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m                                    rounding=rounding)\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_DFS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0m_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;31m# download synchronously\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def update():\n",
    "    import time\n",
    "    from IPython.display import clear_output\n",
    "    while True:\n",
    "        pos_score_company, neg_score_company = technical_scoring_function( live = 'yes', csv_file = 'n50.csv') #live, period, ticker as params\n",
    "        #pos_score_company = sorted(pos_score_company.items(), key=lambda x: x[1], reverse = True)\n",
    "        #neg_score_company = sorted(neg_score_company.items(), key=lambda x: x[1])\n",
    "\n",
    "        #clear_output(wait=True)\n",
    "        print(pos_score_company, datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        #print(neg_score_company)\n",
    "        time.sleep(29)\n",
    "\n",
    "update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    import time\n",
    "    from IPython.display import clear_output\n",
    "    while True:\n",
    "        pos_score_company, neg_score_company = long_term_trend_scoring_function(mode = \"list\", live = 'yes') #live, period, ticker as params\n",
    "        #pos_score_company = sorted(pos_score_company.items(), key=lambda x: x[1], reverse = True)\n",
    "        #neg_score_company = sorted(neg_score_company.items(), key=lambda x: x[1])\n",
    "\n",
    "        #clear_output(wait=True)\n",
    "        print(pos_score_company, datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        #print(neg_score_company)\n",
    "        time.sleep(3)\n",
    "\n",
    "update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_score_column_list = []\n",
    "for col in data.columns:\n",
    "    if(col.startswith('final_score_technical')):\n",
    "        technical_score_column_list.append(col)\n",
    "\n",
    "positive_signal_days = np.where(data[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1) >= 4)\n",
    "negative_signal_days = np.where(data[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1) <= -4)\n",
    "print(\"Positive Signal\\n\",data.iloc[positive_signal_days].index, data.iloc[positive_signal_days][technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "print(\"\\n\\nNegative Signal\",data.iloc[negative_signal_days].index, data.iloc[negative_signal_days][technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "\n",
    "plot_graph(data, g_type='line', mode = 'quick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Getting data for single stock\n",
    "live, g_type = get_user_inputs()\n",
    "data = pull_price_data(live, stock_ticker = 'TATAMOTORS.NS')\n",
    "print(data.index[-1])\n",
    "\n",
    "if(live == 'yes'):\n",
    "    print(\"Is Consolidating: \",is_consolidating(data, percentage=0.5))\n",
    "else:\n",
    "    print(\"Is Consolidating: \",is_consolidating(data))\n",
    "\n",
    "    \n",
    "if(live == 'yes'):\n",
    "    print(\"Is Breaking Out: \",is_breaking_out(data, percentage=2))\n",
    "else:\n",
    "    print(\"Is Breaking Out: \",is_breaking_out(data))    \n",
    "\n",
    "if(live == 'no' or live == 'max'):\n",
    "    data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 1)\n",
    "else:\n",
    "    data, levels, plot_sup_res = finding_signals_from_data(data, time_period_multiplier = 3)\n",
    "#print(levels)\n",
    "data = data[data['Close'].notna()]\n",
    "#plot_graph(data, g_type='line', mode = 'quick')\n",
    "data = plot_graph(data, g_type, mode = 'scoring')\n",
    "\n",
    "\n",
    "\n",
    "technical_score_column_list = []\n",
    "for col in data.columns:\n",
    "    if(col.startswith('final_score_technical')):\n",
    "        technical_score_column_list.append(col)\n",
    "# if(live == 'yes'):\n",
    "#     technical_score_column_list.remove('final_score_technical_DOJI-')\n",
    "#     technical_score_column_list.remove('final_score_technical_DOJI+')\n",
    "    \n",
    "backtest_df = data.copy()\n",
    "long_profit_loss_calculation_df = pd.DataFrame(columns = ['Buy Date', 'Buy Price', 'Buy Signal', \n",
    "                                                          'isDone', 'Sell Date', 'Sell Price',\n",
    "                                                          'Stop Loss', 'Target', 'Profit Percentage'])\n",
    "cur_thresh = 5\n",
    "period = 2\n",
    "for i in range(0 , len(data) - 1, 1):\n",
    "    #Dropping doji for live data\n",
    "    #if(live=='yes'):\n",
    "    #    backtest_df.drop(columns = ['final_score_technical_DOJI-', 'final_score_technical_DOJI+'], inplace = True)\n",
    "        \n",
    "    #df of 2 days to match techincal scoring function      \n",
    "    two_day_score = backtest_df.iloc[i:i+2]\n",
    "    \n",
    "    # Adjusting score for volume\n",
    "    if(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) > 0):\n",
    "        if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "            current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) + 1\n",
    "        else:\n",
    "            current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "    elif(sum(two_day_score.drop(columns = ['final_score_technical_Volume']).sum(axis = 1).values ) < 0):\n",
    "        if(two_day_score['final_score_technical_Volume'].isna().sum() != abs(period)):\n",
    "            current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1)) - 1\n",
    "        else:\n",
    "            current_score = sum(two_day_score[technical_score_column_list].drop(columns = ['final_score_technical_Volume']).sum(axis = 1))\n",
    "    current_market_price = two_day_score['Adj Close'].iloc[-1]\n",
    "    current_date = two_day_score.index[-1]\n",
    "    if(live == 'yes'):\n",
    "        stop_loss_multiplier = 0.997\n",
    "        target_multiplier = 1.008\n",
    "    else:\n",
    "        stop_loss_multiplier = 0.97\n",
    "        target_multiplier = 1.5\n",
    "    if(current_score >= cur_thresh):\n",
    "        temp_row = {\"Buy Date\": current_date, \"Buy Price\": current_market_price, \"Buy Signal\" : current_score, \n",
    "                    \"isDone\" : 0, \"Stop Loss\": current_market_price * stop_loss_multiplier, \n",
    "                    \"Target\" : current_market_price * target_multiplier, \"Threshold\" : cur_thresh,\n",
    "                   \"ticker\" : backtest_ticker}\n",
    "        long_profit_loss_calculation_df = long_profit_loss_calculation_df.append(temp_row, ignore_index = True)\n",
    "    \n",
    "    #Checking if price is above or below SL. Target\n",
    "    if(len(long_profit_loss_calculation_df) > 0):\n",
    "        to_be_checked_df = long_profit_loss_calculation_df[long_profit_loss_calculation_df['isDone'] == 0]\n",
    "        for j in (to_be_checked_df.index):\n",
    "            \n",
    "            if(to_be_checked_df.loc[j]['Target'] < current_market_price):\n",
    "                long_profit_loss_calculation_df.loc[j,\"isDone\"] = 1\n",
    "                long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "                long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "                long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100\n",
    "            elif(to_be_checked_df.loc[j]['Stop Loss'] > current_market_price):\n",
    "                long_profit_loss_calculation_df.loc[j,\"isDone\"] = -1\n",
    "                long_profit_loss_calculation_df.loc[j,\"Sell Date\"] = current_date\n",
    "                long_profit_loss_calculation_df.loc[j,\"Sell Price\"] = current_market_price\n",
    "                long_profit_loss_calculation_df.loc[j,\"Profit Percentage\"] = ((current_market_price - to_be_checked_df.loc[j]['Buy Price'])/to_be_checked_df.loc[j]['Buy Price'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_profit_loss_calculation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_profit_loss_calculation_df['Profit Percentage'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(long_profit_loss_calculation_df[long_profit_loss_calculation_df['Profit Percentage'] > 0]) - len(long_profit_loss_calculation_df[long_profit_loss_calculation_df['Profit Percentage'] < 0]))/len(long_profit_loss_calculation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gen_info = yf.Ticker('INFY.NS').info\n",
    "temp_gen_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_income_statement = yf.Ticker('AUBANK.NS').quarterly_financials/10000000\n",
    "test_income_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balance_sheet = yf.Ticker('AUBANK.NS').quarterly_balance_sheet/10000000\n",
    "test_balance_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_financial_ratios(temp_ticker, term = 365):\n",
    "    try:\n",
    "        test_income_statement = yf.Ticker(temp_ticker).financials/10000000\n",
    "        test_balance_sheet = yf.Ticker(temp_ticker).balance_sheet/10000000\n",
    "        temp_gen_info = yf.Ticker(temp_ticker).info\n",
    "        \n",
    "        # Current and Previous year financials\n",
    "        bs_curr_year = test_balance_sheet.iloc[:,0]\n",
    "        is_curr_year = test_income_statement.iloc[:,0]\n",
    "        bs_prev_year = test_balance_sheet.iloc[:,1]\n",
    "        is_prev_year = test_income_statement.iloc[:,1]\n",
    "    except:\n",
    "        print(t, ' Could not get data')\n",
    "    \n",
    "    fr_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "        # Balance Sheet\n",
    "        try:\n",
    "            current_assets = bs_curr_year['Total Current Assets']\n",
    "        except:\n",
    "            current_assets = np.nan\n",
    "        #current_assets = bs_curr_year['Total Current Assets']\n",
    "\n",
    "        try:\n",
    "            current_liabilities = bs_curr_year['Total Current Liabilities']\n",
    "        except:\n",
    "            current_liabilities = np.nan  \n",
    "        #current_liabilities = bs_curr_year['Total Current Liabilities']\n",
    "\n",
    "        try:\n",
    "            cash = bs_curr_year['Cash']\n",
    "        except:\n",
    "            cash = np.nan \n",
    "        #cash = bs_curr_year['Cash']\n",
    "\n",
    "        try:\n",
    "            short_term_investments = bs_curr_year['Short Term Investments']\n",
    "        except:\n",
    "            short_term_investments = np.nan\n",
    "\n",
    "        try:\n",
    "            accounts_receivable = bs_curr_year['Net Receivables']\n",
    "        except:\n",
    "            accounts_receivable = np.nan\n",
    "\n",
    "        try:\n",
    "            inventory = bs_curr_year['Accounts Payable']\n",
    "        except:\n",
    "            inventory = np.nan\n",
    "\n",
    "        try:\n",
    "            accounts_payable = bs_curr_year['Accounts Payable']\n",
    "        except:\n",
    "            accounts_payable = np.nan\n",
    "        #accounts_payable = bs_curr_year['Accounts Payable']\n",
    "        total_equity = (bs_curr_year['Total Stockholder Equity'] + bs_prev_year['Total Stockholder Equity'])/2\n",
    "        total_assets = bs_curr_year['Total Assets']\n",
    "        total_liabilities = bs_curr_year['Total Liab']\n",
    "        non_current_liabilities = total_liabilities - current_liabilities\n",
    "        ppe = bs_curr_year['Property Plant Equipment']\n",
    "\n",
    "\n",
    "\n",
    "        # Income Statement\n",
    "        revenue = is_curr_year['Total Revenue']    \n",
    "        cogs = is_curr_year['Cost Of Revenue']\n",
    "        gross_profit = is_curr_year['Gross Profit']\n",
    "        operating_income = is_curr_year['Operating Income']\n",
    "        income_before_tax = is_curr_year['Income Before Tax']\n",
    "        net_income = is_curr_year['Net Income']\n",
    "        income_tax_expense = is_curr_year['Income Tax Expense']\n",
    "        ebit = is_curr_year['Ebit']\n",
    "        interest_expense = abs(is_curr_year['Interest Expense'])\n",
    "        operating_income = is_curr_year['Operating Income']\n",
    "\n",
    "\n",
    "        # Liquidity Measurement Ratios\n",
    "        fr_dict['current_ratio'] = current_assets/current_liabilities # A current ratio of 1.0 or greater is an indication that the company is well-positioned to cover its current or short-term liabilities.\n",
    "        fr_dict['DSO'] = (accounts_receivable/revenue)*term #DSO tells you how many days after the sale it takes people to pay you on average.\n",
    "        try:\n",
    "            fr_dict['DIO'] = (inventory/cogs)*term #DIO tells you how many days inventory sits on the shelf on average.\n",
    "        except:\n",
    "            fr_dict['DIO'] = np.nan\n",
    "        fr_dict['operating_cycle'] = fr_dict['DSO'] + fr_dict['DIO'] # (DSO + DIO )Basically the Operating Cycle tells you how many days it takes for something to go from first being in inventory to receiving the cash after the sale.\n",
    "        try:\n",
    "            fr_dict['DPO'] = (accounts_payable/cogs)*term #DPO tells you how many days the company takes to pay its suppliers.\n",
    "        except:\n",
    "            fr_dict['DPO'] = np.nan\n",
    "        fr_dict['CCC'] = fr_dict['operating_cycle'] - fr_dict['DPO'] #The cash conversion cycle (CCC = DSO + DIO – DPO) measures the number of days a company's cash is tied up in the production and sales process of its operations and the benefit it derives from payment terms from its creditors. The shorter this cycle, the more liquid the company's working capital position is. The CCC is also known as the \"cash\" or \"operating\" cycle.\n",
    "\n",
    "        # Profitability Indicator Ratios\n",
    "        fr_dict['gross_profit_margin'] = gross_profit / revenue # You can think of it as the amount of money from product sales left over after all of the direct costs associated with manufacturing the product have been paid.\n",
    "        fr_dict['operating_profit_margin'] = operating_income / revenue # If companies can make enough money from their operations to support the business, the company is usually considered more stable.\n",
    "        fr_dict['pretax_profit_margin'] = income_before_tax / revenue #Profit is the main goal of for-profit organizations. The goal is to make a profit through growth and to grow every year. As a result, one of the most important roles of the financial and investment analyst is to track and forecast profitability.\n",
    "        fr_dict['net_profit_margin'] = net_income / revenue # Generally, a net profit margin in excess of 10% is considered excellent, though it depends on the industry and the structure of the business.\n",
    "        fr_dict['effective_tax_rate'] = income_tax_expense / income_before_tax # If there’s one takeaway, it should be that a company’s tax situation is all but a living, breathing organism in its own right.\n",
    "        fr_dict['return_on_assets'] = net_income / total_assets # ROA Return on assets gives an indication of the capital intensity of the company, which will depend on the industry; companies that require large initial investments will generally have lower return on assets. ROAs over 5% are generally considered good.\n",
    "        fr_dict['ROCE'] = ebit / (total_assets - current_liabilities) # ROCE shows investors how many dollars in profits each dollar of capital employed generates.\n",
    "\n",
    "        # Debt Ratios\n",
    "        fr_dict['debt_ratio'] = total_liabilities / total_assets #T he debt ratio tells us the degree of leverage used by the company.\n",
    "        fr_dict['interest_coverage_ratio'] = ebit / interest_expense # The lower a company’s interest coverage ratio is, the more its debt expenses burden the company.\n",
    "\n",
    "        # Operating Performance Ratios\n",
    "        fr_dict['fixed_asset_turnover'] = revenue / ppe # Calculates how efficiently a company is a producing sales with its machines and equipment.\n",
    "        fr_dict['asset_turnover'] = revenue / total_assets # The Asset Turnover ratio can often be used as an indicator of the efficiency with which a company is deploying its assets in generating revenue.\n",
    "\n",
    "\n",
    "        #in-built ratios\n",
    "        try:\n",
    "            fr_dict['twoHundredDayAverage'] = temp_gen_info['twoHundredDayAverage']\n",
    "        except:\n",
    "            fr_dict['twoHundredDayAverage'] = np.nan\n",
    "        #fr_dict['twoHundredDayAverage'] = temp_gen_info['twoHundredDayAverage']\n",
    "\n",
    "        try:\n",
    "            fr_dict['payoutRatio'] = temp_gen_info['payoutRatio']\n",
    "        except:\n",
    "            fr_dict['payoutRatio'] = np.nan\n",
    "        #fr_dict['payoutRatio'] = temp_gen_info['payoutRatio']\n",
    "\n",
    "        try:\n",
    "            fr_dict['fiftyDayAverage'] = temp_gen_info['fiftyDayAverage']\n",
    "        except:\n",
    "            fr_dict['fiftyDayAverage'] = np.nan\n",
    "        #fr_dict['fiftyDayAverage'] = temp_gen_info['fiftyDayAverage']\n",
    "\n",
    "        try:\n",
    "            fr_dict['trailingAnnualDividendRate'] = temp_gen_info['trailingAnnualDividendRate']\n",
    "        except:\n",
    "            fr_dict['trailingAnnualDividendRate'] = np.nan\n",
    "        #fr_dict['trailingAnnualDividendRate'] = temp_gen_info['trailingAnnualDividendRate']\n",
    "\n",
    "        try:\n",
    "            fr_dict['dividendRate'] = temp_gen_info['dividendRate']\n",
    "        except:\n",
    "            fr_dict['dividendRate'] = np.nan\n",
    "        #fr_dict['dividendRate'] = temp_gen_info['dividendRate']\n",
    "\n",
    "        try:\n",
    "            fr_dict['trailing_PE'] = temp_gen_info['trailingPE']\n",
    "        except:\n",
    "            fr_dict['trailing_PE'] = np.nan\n",
    "        #fr_dict['trailing_PE'] = temp_gen_info['trailingPE']\n",
    "\n",
    "        try:\n",
    "            fr_dict['market_cap'] = temp_gen_info['marketCap']\n",
    "        except:\n",
    "            fr_dict['market_cap'] = np.nan\n",
    "        #fr_dict['market_cap'] = temp_gen_info['marketCap']\n",
    "\n",
    "        try:\n",
    "            fr_dict['priceToSalesTrailing12Months'] = temp_gen_info['priceToSalesTrailing12Months']\n",
    "        except:\n",
    "            fr_dict['priceToSalesTrailing12Months'] = np.nan\n",
    "        #fr_dict['priceToSalesTrailing12Months'] = temp_gen_info['priceToSalesTrailing12Months']\n",
    "\n",
    "        try:\n",
    "            fr_dict['forward_PE'] = temp_gen_info['forwardPE']\n",
    "        except:\n",
    "            fr_dict['forward_PE'] = np.nan\n",
    "        #fr_dict['forward_PE'] = temp_gen_info['forwardPE']\n",
    "\n",
    "        try:\n",
    "            fr_dict['fiftyTwoWeekHigh'] = temp_gen_info['fiftyTwoWeekHigh']\n",
    "        except:\n",
    "            fr_dict['fiftyTwoWeekHigh'] = np.nan\n",
    "        #fr_dict['fiftyTwoWeekHigh'] = temp_gen_info['fiftyTwoWeekHigh']\n",
    "\n",
    "        try:\n",
    "            fr_dict['fiftyTwoWeekLow'] = temp_gen_info['fiftyTwoWeekLow']\n",
    "        except:\n",
    "            fr_dict['fiftyTwoWeekLow'] = np.nan\n",
    "        #fr_dict['fiftyTwoWeekLow'] = temp_gen_info['fiftyTwoWeekLow']\n",
    "\n",
    "        try:\n",
    "            fr_dict['enterpriseToRevenue'] = temp_gen_info['enterpriseToRevenue']\n",
    "        except:\n",
    "            fr_dict['enterpriseToRevenue'] = np.nan\n",
    "        #fr_dict['enterpriseToRevenue'] = temp_gen_info['enterpriseToRevenue']\n",
    "\n",
    "        try:\n",
    "            fr_dict['profitMargins'] = temp_gen_info['profitMargins']\n",
    "        except:\n",
    "            fr_dict['profitMargins'] = np.nan\n",
    "        #fr_dict['profitMargins'] = temp_gen_info['profitMargins']\n",
    "\n",
    "        try:\n",
    "            fr_dict['enterpriseToEbitda'] = temp_gen_info['enterpriseToEbitda']\n",
    "        except:\n",
    "            fr_dict['enterpriseToEbitda'] = np.nan\n",
    "        #fr_dict['enterpriseToEbitda'] = temp_gen_info['enterpriseToEbitda']\n",
    "\n",
    "        try:\n",
    "            fr_dict['trailing_EPS'] = temp_gen_info['trailingEps']\n",
    "        except:\n",
    "            fr_dict['trailing_EPS'] = np.nan\n",
    "        fr_dict['forward_EPS'] = temp_gen_info['forwardEps']\n",
    "        fr_dict['bookValue'] = temp_gen_info['bookValue']\n",
    "        fr_dict['priceToBook'] = temp_gen_info['priceToBook']\n",
    "        fr_dict['cmp'] = temp_gen_info['regularMarketPrice']\n",
    "    except:\n",
    "        print(temp_ticker,\" Errored out\")\n",
    "    return(fr_dict)\n",
    "\n",
    "def create_df_of_financial_ratios(csv_file = 'n200.csv'):\n",
    "    frames = []\n",
    "    n50 = pd.read_csv(csv_file)\n",
    "    n50 = n50[['Industry', 'Symbol']]\n",
    "    n50['Symbol'] = n50['Symbol'].apply(lambda x: x + '.NS')\n",
    "    i=1\n",
    "    for sector, t in n50.values:\n",
    "        print(i, t)\n",
    "        i = i + 1\n",
    "        ratio_data_single_ticker = calculate_financial_ratios(t)\n",
    "        temp_df = pd.DataFrame(ratio_data_single_ticker, index=[t])\n",
    "        temp_df['Sector'] = sector\n",
    "        frames.append(temp_df)\n",
    "    return(pd.concat(frames))\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "combined_financial_ratio_df = create_df_of_financial_ratios('n500.csv')\n",
    "print('Time taken : ',datetime.datetime.now() - start)\n",
    "\n",
    "\n",
    "\n",
    "#combined_financial_ratio_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving df\n",
    "combined_financial_ratio_df.to_csv('annual_financial_ratio_n500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Ratio df (29/05/2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = pd.read_csv('annual_financial_ratio_n500.csv', index_col=0)\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ROCE d\n",
    "operating profit margin d\n",
    "EPS d\n",
    "fixed asset turnover d\n",
    "market_cap d\n",
    "payoutRatio d\n",
    "\n",
    "debt ratio a\n",
    "PE a\n",
    "enterpriseToEbitda(ev to ebitda) a\n",
    "enterpriseToRevenue a\n",
    "\n",
    "'''\n",
    "\n",
    "imp_financial_df = asdf[['ROCE', 'debt_ratio', 'operating_profit_margin', 'net_profit_margin', 'trailing_PE', 'forward_PE',\n",
    "                         'trailing_EPS', 'forward_EPS', 'enterpriseToEbitda', 'fixed_asset_turnover',\n",
    "                         'enterpriseToRevenue', 'market_cap', 'payoutRatio', 'cmp', 'fiftyTwoWeekHigh', \n",
    "                         'fiftyTwoWeekLow', 'twoHundredDayAverage', 'fiftyDayAverage','Sector']].dropna(thresh=10)\n",
    "imp_financial_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_financial_df['Sector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_financial_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Financial Ratio Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imp_financial_df['cmp'] / imp_financial_df['fiftyTwoWeekHigh']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = pd.read_csv('annual_financial_ratio_n500.csv', index_col=0)\n",
    "imp_financial_df = asdf[['ROCE', 'debt_ratio', 'operating_profit_margin', 'net_profit_margin', 'trailing_PE', 'forward_PE',\n",
    "                         'trailing_EPS', 'forward_EPS', 'enterpriseToEbitda', 'fixed_asset_turnover',\n",
    "                         'enterpriseToRevenue', 'market_cap', 'payoutRatio', 'cmp', 'fiftyTwoWeekHigh', \n",
    "                         'fiftyTwoWeekLow', 'twoHundredDayAverage', 'fiftyDayAverage','Sector']].dropna(thresh=10)\n",
    "\n",
    "# Rank for higher the better metrics\n",
    "for col in ['ROCE', 'operating_profit_margin', 'net_profit_margin', 'trailing_EPS', 'fixed_asset_turnover', 'market_cap', 'payoutRatio']:\n",
    "    imp_financial_df['score_' + col] = imp_financial_df[col].rank()\n",
    "\n",
    "# Rank for lower the better metrics    \n",
    "for col in ['debt_ratio', 'trailing_PE', 'enterpriseToEbitda', 'enterpriseToRevenue']:\n",
    "    imp_financial_df['score_' + col] = imp_financial_df[col].rank(ascending  = False)\n",
    "\n",
    "# Custom ranks\n",
    "imp_financial_df['score_close_to_52_week_high'] = (imp_financial_df['cmp'] / imp_financial_df['fiftyTwoWeekHigh']).rank(ascending  = False)\n",
    "    \n",
    "\n",
    "imp_financial_score_df = imp_financial_df.drop(columns = ['ROCE', 'debt_ratio', 'operating_profit_margin', 'net_profit_margin', 'trailing_PE', 'forward_PE',\n",
    "                         'trailing_EPS', 'forward_EPS', 'enterpriseToEbitda', 'fixed_asset_turnover',\n",
    "                         'enterpriseToRevenue', 'market_cap', 'payoutRatio', 'cmp', 'fiftyTwoWeekHigh', \n",
    "                         'fiftyTwoWeekLow', 'twoHundredDayAverage', 'fiftyDayAverage'])\n",
    "imp_financial_score_df['final_score'] = imp_financial_score_df.drop(columns = ['Sector']).sum(axis = 1)\n",
    "imp_financial_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Sector Mean (Higher the better)\n",
    "imp_financial_score_df.groupby(['Sector']).mean()['final_score'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_financial_score_df.sort_values('final_score', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_sector = 'PHARMA'\n",
    "req_index = imp_financial_score_df[imp_financial_score_df['Sector'] == req_sector].sort_values('final_score', ascending=False).index\n",
    "asdf[['ROCE', 'debt_ratio', 'operating_profit_margin', 'net_profit_margin', 'trailing_PE', 'forward_PE',\n",
    "                         'trailing_EPS', 'forward_EPS', 'enterpriseToEbitda', 'fixed_asset_turnover',\n",
    "                         'enterpriseToRevenue', 'market_cap', 'payoutRatio', 'cmp', 'fiftyTwoWeekHigh', \n",
    "                         'fiftyTwoWeekLow', 'twoHundredDayAverage', 'fiftyDayAverage','Sector']].dropna(thresh=10).loc[req_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
